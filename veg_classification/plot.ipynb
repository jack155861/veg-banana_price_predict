{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe488c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import pandas as pd\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "def swish(x, beta = 1):\n",
    "    # https://www.geeksforgeeks.org/ml-swish-function-by-google-in-keras/\n",
    "    return (x * sigmoid(beta * x))\n",
    "def leaky_relu(x):\n",
    "    return tf.nn.leaky_relu(x, alpha=0.25)\n",
    "def get_weighted_loss(weights):\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    return weighted_loss\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "get_custom_objects().update({'swish': swish})\n",
    "get_custom_objects().update({'leaky_relu': leaky_relu})\n",
    "get_custom_objects().update({\"get_weighted_loss\": get_weighted_loss})\n",
    "get_custom_objects().update({\"weighted_loss\": weighted_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edf5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "banana_X_train = pd.read_pickle(\"veg_X_train.pkl\")\n",
    "banana_X_val = pd.read_pickle(\"veg_X_val.pkl\")\n",
    "banana_Y_train = pd.read_pickle(\"veg_Y_train.pkl\")\n",
    "banana_Y_val = pd.read_pickle(\"veg_Y_val.pkl\")\n",
    "cols_name = [[y+'-'+str(x).rjust(2,\"0\") for x in range(1,31)] for y in ['RSV','上價中位數','下價中位數','中價中位數','交易量','平均價','雨量']]\n",
    "cols_name_2 = [x for x in banana_X_train.columns.tolist() if '-' not in x]\n",
    "\n",
    "train_X_num = banana_X_train[cols_name_2[1:]].values\n",
    "val_X_num = banana_X_val[cols_name_2[1:]].values\n",
    "\n",
    "train_Y_1 = banana_Y_train[[x for x in banana_Y_train.columns if '成本價格' in x]].values\n",
    "val_Y_1 = banana_Y_val[[x for x in banana_Y_val.columns if '成本價格' in x]].values\n",
    "\n",
    "train_X_lstm_1 = []\n",
    "for i in range(len(cols_name)):\n",
    "    tmp = banana_X_train[cols_name[i]].iloc[:,-7:]\n",
    "    train_X_lstm_1.append(tmp)\n",
    "train_X_lstm_1 = np.stack(train_X_lstm_1,axis=2)\n",
    "val_X_lstm_1 = []\n",
    "for i in range(len(cols_name)):\n",
    "    tmp = banana_X_val[cols_name[i]].iloc[:,-7:]\n",
    "    val_X_lstm_1.append(tmp)\n",
    "val_X_lstm_1 = np.stack(val_X_lstm_1,axis=2)\n",
    "\n",
    "train_X_lstm_2 = []\n",
    "for i in range(len(cols_name)):\n",
    "    tmp_all = []\n",
    "    tmp = banana_X_train[cols_name[i]].iloc[:,-13:]\n",
    "    for j in range(7):\n",
    "        tmp_1 = tmp.iloc[:,j:j+7]\n",
    "        tmp_all.append(tmp_1)\n",
    "    tmp_all = np.stack(tmp_all,axis=2)\n",
    "    train_X_lstm_2.append(tmp_all)\n",
    "train_X_lstm_2 = np.stack(train_X_lstm_2,axis=3)\n",
    "\n",
    "val_X_lstm_2 = []\n",
    "for i in range(len(cols_name)):\n",
    "    tmp_all = []\n",
    "    tmp = banana_X_val[cols_name[i]].iloc[:,-13:]\n",
    "    for j in range(7):\n",
    "        tmp_1 = tmp.iloc[:,j:j+7]\n",
    "        tmp_all.append(tmp_1)\n",
    "    tmp_all = np.stack(tmp_all,axis=2)\n",
    "    val_X_lstm_2.append(tmp_all)\n",
    "val_X_lstm_2 = np.stack(val_X_lstm_2,axis=3)\n",
    "\n",
    "train_X_lstm_4 = np.stack([np.stack([image_convert(x) for x in banana_X_train[cols_name[y]].values]) for y in range(len(cols_name))], axis=3)\n",
    "val_X_lstm_4 = np.stack([np.stack([image_convert(x) for x in banana_X_val[cols_name[y]].values]) for y in range(len(cols_name))], axis=3)\n",
    "\n",
    "data_X = {'Conv1D':[train_X_lstm_1, val_X_lstm_1],\n",
    "          'Vanilla':[train_X_lstm_1, val_X_lstm_1],\n",
    "          'Stacked':[train_X_lstm_1, val_X_lstm_1],\n",
    "          'Bidirectional':[train_X_lstm_1, val_X_lstm_1],\n",
    "          'Conv1D_LSTM':[train_X_lstm_2, val_X_lstm_2],\n",
    "          'Conv2D_1':[train_X_lstm_2, val_X_lstm_2],\n",
    "          'Conv2D_2':[train_X_lstm_4, val_X_lstm_4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554d9f2d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer times_lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 10:28:31.366360: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1cacb940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-09-29 10:28:31.366439: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2022-09-29 10:28:31.382533: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-09-29 10:28:32.140915: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-09-29 10:28:33.199443: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "weight = 'model/Conv1D_LSTM/0-sgd-relu-relu/weights_accuracy.hdf5'\n",
    "model = load_model(weight)\n",
    "data_train = model.predict([data_X[\"Conv1D_LSTM\"][1],val_X_num], verbose = 0)\n",
    "\n",
    "before = banana_Y_val[['成本價格-02', '成本價格-03', '成本價格-04', '成本價格-05', '成本價格-06']].values\n",
    "after = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8e0878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ax = plt.subplots(figsize=(7, 8))\n",
    "\n",
    "# For each class\n",
    "colors = cycle([\"navy\", \"turquoise\", \"darkorange\", \"cornflowerblue\", \"teal\"])\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(5):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(before[:, i], after[:, i])\n",
    "    average_precision[i] = average_precision_score(before[:, i], after[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
    "    before.ravel(), after.ravel()\n",
    ")\n",
    "average_precision[\"micro\"] = average_precision_score(before, after, average=\"micro\")\n",
    "\n",
    "display = PrecisionRecallDisplay(\n",
    "    recall=recall[\"micro\"],\n",
    "    precision=precision[\"micro\"],\n",
    "    average_precision=average_precision[\"micro\"],\n",
    ")\n",
    "display.plot(ax=ax, name=\"Micro-average PR value\", color=\"gold\")\n",
    "\n",
    "for i, color in zip(range(5), colors):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[i],\n",
    "        precision=precision[i],\n",
    "        average_precision=average_precision[i],\n",
    "    )\n",
    "    display.plot(ax=ax, name=f\"PR value for after day {i}\", color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c167f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8087e1d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 11:28:33.698158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 11:28:33.939417: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-29 11:28:40.118538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-29 11:28:40.118669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-29 11:28:40.118678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipywidgets\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_learning_phase(True)\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3ffde0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer times_lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "2022-09-29 11:29:55.107446: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"/home/jack155861/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\", line 252, in grad_graph  *\n        x_grad = tape.gradient(out, shap_rAnD)\n\n    LookupError: gradient registry has no entry for: shap_TensorListStack\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(weight,\u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model, [data_X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv1D_LSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],train_X_num], learning_phase_flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv1D_LSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_X_num\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py:124\u001b[0m, in \u001b[0;36mDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124;03m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m        were chosen as \"top\".\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:312\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# run attribution computation graph\u001b[39;00m\n\u001b[1;32m    311\u001b[0m feature_ind \u001b[38;5;241m=\u001b[39m model_output_ranks[j,i]\n\u001b[0;32m--> 312\u001b[0m sample_phis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi_symbolic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:372\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    369\u001b[0m         tf_execute\u001b[38;5;241m.\u001b[39mrecord_gradient \u001b[38;5;241m=\u001b[39m tf_backprop\u001b[38;5;241m.\u001b[39mrecord_gradient\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_out\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_with_overridden_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43manon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:408\u001b[0m, in \u001b[0;36mTFDeep.execute_with_overridden_gradients\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# reinstate the backpropagatable check\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tf_gradients_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_IsBackpropagatable\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:365\u001b[0m, in \u001b[0;36mTFDeep.run.<locals>.anon\u001b[0;34m()\u001b[0m\n\u001b[1;32m    363\u001b[0m     v \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs[i]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    364\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[0;32m--> 365\u001b[0m final_out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     tf_execute\u001b[38;5;241m.\u001b[39mrecord_gradient \u001b[38;5;241m=\u001b[39m tf_backprop\u001b[38;5;241m.\u001b[39m_record_gradient\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1233\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1234\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    File \"/home/jack155861/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\", line 252, in grad_graph  *\n        x_grad = tape.gradient(out, shap_rAnD)\n\n    LookupError: gradient registry has no entry for: shap_TensorListStack\n"
     ]
    }
   ],
   "source": [
    "weight = 'model/Conv1D_LSTM/0-sgd-relu-relu/weights_accuracy.hdf5'\n",
    "model = load_model(weight,compile=False)\n",
    "explainer = shap.DeepExplainer(model, [data_X[\"Conv1D_LSTM\"][0],train_X_num], learning_phase_flags = None)\n",
    "a = explainer.shap_values([data_X[\"Conv1D_LSTM\"][0][0:1,:,:,:],train_X_num[0:1,:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63099d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, [data_X[\"Conv1D_LSTM\"][0][0:2,:,:,:],train_X_num[0:2,:]], learning_phase_flags = None)\n",
    "#explainer = shap.KernelExplainer(simple_model_only_first_output, [data_X[\"Conv1D_LSTM\"][0],train_X_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172c5b0c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"/home/jack155861/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\", line 252, in grad_graph  *\n        x_grad = tape.gradient(out, shap_rAnD)\n\n    LookupError: gradient registry has no entry for: shap_TensorListStack\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv1D_LSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_X_num\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py:124\u001b[0m, in \u001b[0;36mDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124;03m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m        were chosen as \"top\".\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:312\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# run attribution computation graph\u001b[39;00m\n\u001b[1;32m    311\u001b[0m feature_ind \u001b[38;5;241m=\u001b[39m model_output_ranks[j,i]\n\u001b[0;32m--> 312\u001b[0m sample_phis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi_symbolic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:372\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    369\u001b[0m         tf_execute\u001b[38;5;241m.\u001b[39mrecord_gradient \u001b[38;5;241m=\u001b[39m tf_backprop\u001b[38;5;241m.\u001b[39mrecord_gradient\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_out\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_with_overridden_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43manon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:408\u001b[0m, in \u001b[0;36mTFDeep.execute_with_overridden_gradients\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# reinstate the backpropagatable check\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tf_gradients_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_IsBackpropagatable\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:365\u001b[0m, in \u001b[0;36mTFDeep.run.<locals>.anon\u001b[0;34m()\u001b[0m\n\u001b[1;32m    363\u001b[0m     v \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs[i]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    364\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[0;32m--> 365\u001b[0m final_out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     tf_execute\u001b[38;5;241m.\u001b[39mrecord_gradient \u001b[38;5;241m=\u001b[39m tf_backprop\u001b[38;5;241m.\u001b[39m_record_gradient\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1233\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1234\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    File \"/home/jack155861/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\", line 252, in grad_graph  *\n        x_grad = tape.gradient(out, shap_rAnD)\n\n    LookupError: gradient registry has no entry for: shap_TensorListStack\n"
     ]
    }
   ],
   "source": [
    "explainer.shap_values([data_X[\"Conv1D_LSTM\"][0][0:2,:,:,:],train_X_num[0:2,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b313512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'dense_3')>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cb992d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#explainer = shap.explainers.Permutation(model, max_evals = 2671971)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv1D_LSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_X_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# visualize the first prediction's explanation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m shap\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mwaterfall(shap_values[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_permutation.py:82\u001b[0m, in \u001b[0;36mPermutation.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, main_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m              outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124;03m\"\"\" Explain the output of the model on the given arguments.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_explainer.py:266\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args))]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[0;32m--> 266\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    271\u001b[0m     output_indices\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_permutation.py:140\u001b[0m, in \u001b[0;36mPermutation.explain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m    137\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# evaluate the masked model\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     row_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(fm),) \u001b[38;5;241m+\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/utils/_masked_model.py:64\u001b[0m, in \u001b[0;36mMaskedModel.__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m         full_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_masker_cols), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m     63\u001b[0m         _convert_delta_mask_to_full(masks, full_masks)\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_full_masking_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_masking_call(masks, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/utils/_masked_model.py:93\u001b[0m, in \u001b[0;36mMaskedModel._full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     91\u001b[0m     masked_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker(delta_ind, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     masked_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# get a copy that won't get overwritten by the next iteration \u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimmutable_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "#explainer = shap.explainers.Permutation(model, max_evals = 2671971)\n",
    "\n",
    "shap_values = explainer([data_X[\"Conv1D_LSTM\"][1][:5],val_X_num[:5].reshape((5,21))], max_evals = 50000)\n",
    "# visualize the first prediction's explanation\n",
    "\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719bcdf0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensors are unhashable (this tensor: KerasTensor(type_spec=TensorSpec(shape=(?, 7, 7, 7), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")). Instead, use tensor.ref() as the key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m simple_model_only_first_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m      2\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minputs,\n\u001b[1;32m      3\u001b[0m     outputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# specifying a single output for shap usage\u001b[39;00m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimple_model_only_first_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv1D_LSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_X_num\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py:84\u001b[0m, in \u001b[0;36mDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     81\u001b[0m         framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mTFDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_phase_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:158\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m    156\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have provided over 5k background samples! For better performance consider using smaller random sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m#if type(self.model)is tuple:\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m#    self.fModel(cnn.inputs, cnn.get_layer(theNameYouWant).outputs)\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:349\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m\"\"\" Runs the model while also setting the learning phase flags to False.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 349\u001b[0m     feed_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_phase_flags:\n\u001b[1;32m    351\u001b[0m         feed_dict[t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/keras_tensor.py:268\u001b[0m, in \u001b[0;36mKerasTensor.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensors are unhashable (this tensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead, use tensor.ref() as the key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensors are unhashable (this tensor: KerasTensor(type_spec=TensorSpec(shape=(?, 7, 7, 7), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")). Instead, use tensor.ref() as the key."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shap_values = explainer.shap_values([data_X[\"Conv1D_LSTM\"][1],val_X_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca739cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d09bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, [data_X[\"Conv1D_LSTM\"][0],train_X_num])\n",
    "#shap_values = explainer.shap_values([data_X[\"Conv1D_LSTM\"][1][:5],val_X_num[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc414d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d34358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1e87af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.rnn.time_distributed.TimeDistributed at 0x7f1a44531700>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.Explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cd18f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 7, 7, 7)]    0           []                               \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 7, 7, 64)    960         ['input_1[0][0]']                \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 7, 7, 64)    256         ['time_distributed[0][0]']       \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 7, 7, 64)    0           ['time_distributed_1[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 7, 7, 64)    8256        ['time_distributed_2[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 7, 7, 64)    256         ['time_distributed_3[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDistri  (None, 7, 7, 64)    0           ['time_distributed_4[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 7, 3, 64)    0           ['time_distributed_5[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 7, 3, 32)    4128        ['time_distributed_6[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 7, 3, 32)    128         ['time_distributed_7[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 7, 3, 32)    0           ['time_distributed_8[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeDistr  (None, 7, 3, 32)    2080        ['time_distributed_9[0][0]']     \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " time_distributed_11 (TimeDistr  (None, 7, 3, 32)    128         ['time_distributed_10[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeDistr  (None, 7, 3, 32)    0           ['time_distributed_11[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeDistr  (None, 7, 1, 32)    0           ['time_distributed_12[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " time_distributed_14 (TimeDistr  (None, 7, 32)       0           ['time_distributed_13[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " times_lstm_1 (LSTM)            (None, 50)           16600       ['time_distributed_14[0][0]']    \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 21)]         0           []                               \n",
      "                                                                                                  \n",
      " times_dense_1 (Dense)          (None, 1024)         52224       ['times_lstm_1[0][0]']           \n",
      "                                                                                                  \n",
      " non_times_dense_1 (Dense)      (None, 1024)         22528       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " times_dense_2 (Dense)          (None, 256)          262400      ['times_dense_1[0][0]']          \n",
      "                                                                                                  \n",
      " non_times_dense_2 (Dense)      (None, 256)          262400      ['non_times_dense_1[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512)          0           ['times_dense_2[0][0]',          \n",
      "                                                                  'non_times_dense_2[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         525312      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          262400      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           16448       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5)            325         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,436,829\n",
      "Trainable params: 1,436,445\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf7fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = shap.utils.hclust(X.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e4602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  5.        ,  0.03998143,  2.        ],\n",
       "       [ 7.        , 12.        ,  0.57783765,  3.        ],\n",
       "       [ 1.        ,  4.        ,  0.61038065,  2.        ],\n",
       "       [ 2.        , 14.        ,  0.64025795,  3.        ],\n",
       "       [ 0.        , 13.        ,  0.65362942,  4.        ],\n",
       "       [15.        , 16.        ,  0.82917935,  7.        ],\n",
       "       [11.        , 17.        ,  0.85548913,  8.        ],\n",
       "       [10.        , 18.        ,  0.87416458,  9.        ],\n",
       "       [ 8.        , 19.        ,  0.95298803, 10.        ],\n",
       "       [ 9.        , 20.        ,  0.97237563, 11.        ],\n",
       "       [ 6.        , 21.        ,  0.97623998, 12.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc10370f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82891bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 688]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# build a clustering of the features based on shared information about y\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m clustering \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhclust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv1D_LSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_X_num\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_Y_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# above we implicitly used shap.maskers.Independent by passing a raw dataframe as the masker\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# now we explicitly use a Partition masker that uses the clustering we just computed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m masker \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mmaskers\u001b[38;5;241m.\u001b[39mPartition(data_X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv1D_LSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m], clustering\u001b[38;5;241m=\u001b[39mclustering)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/utils/_clustering.py:150\u001b[0m, in \u001b[0;36mhclust\u001b[0;34m(X, y, linkage, metric, random_state)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# build the distance matrix\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost_distances_r2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 150\u001b[0m     dist_full \u001b[38;5;241m=\u001b[39m \u001b[43mxgboost_distances_r2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# build a condensed upper triangular version by taking the max distance from either direction\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     dist \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/shap/utils/_clustering.py:104\u001b[0m, in \u001b[0;36mxgboost_distances_r2\u001b[0;34m(X, y, learning_rate, early_stopping_rounds, subsample, max_estimators, random_state)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# pick our train/text split\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m X_train,X_test,y_train,y_test \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# fit an XGBoost model on each of the features\u001b[39;00m\n\u001b[1;32m    107\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:2172\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2172\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2174\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2175\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m   2176\u001b[0m                                           default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:356\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    List of objects to ensure sliceability.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 356\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:319\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths])\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 688]"
     ]
    }
   ],
   "source": [
    "# build a clustering of the features based on shared information about y\n",
    "clustering = shap.utils.hclust([data_X[\"Conv1D_LSTM\"][1],val_X_num], val_Y_1)\n",
    "# above we implicitly used shap.maskers.Independent by passing a raw dataframe as the masker\n",
    "# now we explicitly use a Partition masker that uses the clustering we just computed\n",
    "masker = shap.maskers.Partition(data_X[\"Conv1D_LSTM\"][1], clustering=clustering)\n",
    "\n",
    "# build a Permutation explainer and explain the model predictions on the given dataset\n",
    "explainer = shap.explainers.Permutation(model, masker)\n",
    "#shap_values2 = explainer(X[:100])\n",
    "\n",
    "# get just the explanations for the positive class\n",
    "#shap_values2 = shap_values2[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
